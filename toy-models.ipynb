{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d97a7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass, replace\n",
    "import numpy as np\n",
    "import einops\n",
    "from tqdm.notebook import trange\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f0a2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "  n_features: int\n",
    "  n_hidden: int\n",
    "  n_experts: int # total number of experts\n",
    "  n_active_experts:int  # no of active experts\n",
    "  load_balancing_loss: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60e2327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoEModel(nn.Module):\n",
    "  def __init__(self, \n",
    "               config, \n",
    "               feature_probability: Optional[torch.Tensor] = None,\n",
    "               importance: Optional[torch.Tensor] = None,               \n",
    "               device='cuda'):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "    self.W_experts = nn.Parameter(torch.empty((config.n_experts, config.n_features, config.n_hidden), device=device))\n",
    "    nn.init.xavier_normal_(self.W_experts)\n",
    "    self.b_final = nn.Parameter(torch.zeros((config.n_experts, config.n_features), device=device))\n",
    "    self.gate = nn.Parameter(torch.zeros((config.n_experts, config.n_features), device=device))\n",
    "\n",
    "    if feature_probability is None:\n",
    "      feature_probability = torch.ones(())\n",
    "    self.feature_probability = feature_probability.to(device)\n",
    "    if importance is None:\n",
    "      importance = torch.ones(())\n",
    "    self.importance = importance.to(device)\n",
    "\n",
    "  def compute_active_experts(self, features):   \n",
    "    # features: [..., n_features]\n",
    "    # gate: [n_experts, n_features]     \n",
    "    gate_scores = torch.einsum(\"...f,ef->...e\", features, self.gate)\n",
    "    gate_probs = F.softmax(gate_scores, dim=-1)\n",
    "    \n",
    "    top_k_values, top_k_indices = torch.topk(gate_probs, k=self.config.n_active_experts, dim=-1)\n",
    "    active_mask = torch.zeros_like(gate_probs)\n",
    "    active_mask.scatter_(-1, top_k_indices, 1.0)\n",
    "    \n",
    "    load_balance_loss = None\n",
    "    if self.config.load_balancing_loss:\n",
    "      # P_i: average router probability for expert i (before top-k selection)\n",
    "      P_i = torch.mean(gate_probs, dim=tuple(range(gate_probs.dim() - 1)))\n",
    "      \n",
    "      # f_i: fraction of tokens actually dispatched to expert i (after top-k selection)\n",
    "      f_i = torch.mean(active_mask, dim=tuple(range(active_mask.dim() - 1)))\n",
    "      \n",
    "      N = self.config.n_experts\n",
    "      alpha = 0.01\n",
    "      load_balance_loss = alpha * N * torch.sum(f_i * P_i)\n",
    "    \n",
    "    # renormalize gating weights for active experts only\n",
    "    # sum of probabilities for active experts\n",
    "    active_sum = torch.sum(gate_probs * active_mask, dim=-1, keepdim=True)\n",
    "    \n",
    "    renormalized_weights = torch.where(\n",
    "        active_mask.bool(),\n",
    "        gate_probs / active_sum,\n",
    "        torch.zeros_like(gate_probs)\n",
    "    )\n",
    "    return renormalized_weights, top_k_indices, load_balance_loss\n",
    "\n",
    "\n",
    "  def forward(self, features):\n",
    "    # features: [..., n_features]    \n",
    "\n",
    "    expert_weights, top_k_indices, load_balance_loss = self.compute_active_experts(features)\n",
    "    \n",
    "    # hidden: [..., n_experts, n_hidden] - compression\n",
    "    hidden = torch.einsum(\"...f,efh->...eh\", features, self.W_experts)\n",
    "    \n",
    "    # expert_outputs: [..., n_experts, n_features]\n",
    "    expert_outputs = torch.einsum(\"...eh,efh->...ef\", hidden, self.W_experts)\n",
    "    expert_outputs = expert_outputs + self.b_final\n",
    "    expert_outputs = F.relu(expert_outputs)\n",
    "  \n",
    "    # final_output: [..., n_features] - recons\n",
    "    final_output = torch.einsum(\"...e,...ef->...f\", expert_weights, expert_outputs)\n",
    "    return final_output, load_balance_loss\n",
    "\n",
    "  def generate_batch(self, n_batch):\n",
    "    feat = torch.rand((n_batch, self.config.n_features), device=self.W_experts.device)\n",
    "    batch = torch.where(\n",
    "        torch.rand((n_batch, self.config.n_features), device=self.W_experts.device) <= self.feature_probability,\n",
    "        feat,\n",
    "        torch.zeros((), device=self.W_experts.device),\n",
    "    )\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_lr(step, steps):\n",
    "  return (1 - (step / steps))\n",
    "\n",
    "def constant_lr(*_):\n",
    "  return 1.0\n",
    "\n",
    "def cosine_decay_lr(step, steps):\n",
    "  return np.cos(0.5 * np.pi * step / (steps - 1))\n",
    "\n",
    "def optimize(model, \n",
    "             render=False, \n",
    "             n_batch=1024,\n",
    "             steps=10_000,\n",
    "             print_freq=100,\n",
    "             lr=1e-3,\n",
    "             lr_scale=constant_lr,\n",
    "             hooks=[]):\n",
    "  cfg = model.config\n",
    "\n",
    "  opt = torch.optim.AdamW(list(model.parameters()), lr=lr)\n",
    "\n",
    "  start = time.time()\n",
    "  with trange(steps) as t:\n",
    "    for step in t:\n",
    "      step_lr = lr * lr_scale(step, steps)\n",
    "      for group in opt.param_groups:\n",
    "        group['lr'] = step_lr\n",
    "      opt.zero_grad(set_to_none=True)\n",
    "      batch = model.generate_batch(n_batch)\n",
    "      out, load_balance_loss = model(batch)\n",
    "      error = (model.importance*(batch.abs() - out)**2)\n",
    "      reconstruction_loss = einops.reduce(error, 'b f -> f', 'mean').sum()\n",
    "      \n",
    "      loss = reconstruction_loss\n",
    "      if load_balance_loss is not None:\n",
    "        loss = loss + load_balance_loss\n",
    "      \n",
    "      loss.backward()\n",
    "      opt.step()\n",
    "    \n",
    "      if hooks:\n",
    "        hook_data = dict(model=model,\n",
    "                         step=step, \n",
    "                         opt=opt,\n",
    "                         error=error,\n",
    "                         loss=loss,\n",
    "                         reconstruction_loss=reconstruction_loss,\n",
    "                         load_balance_loss=load_balance_loss,\n",
    "                         lr=step_lr)\n",
    "        for h in hooks:\n",
    "          h(hook_data)\n",
    "      if step % print_freq == 0 or (step + 1 == steps):\n",
    "        t.set_postfix(\n",
    "            loss=loss.item(),\n",
    "            lr=step_lr,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c3de005",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  DEVICE = 'cuda'\n",
    "else:\n",
    "  DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98fc3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    n_features = 5,\n",
    "    n_hidden = 2,\n",
    "    n_experts = 10,\n",
    "    n_active_experts = 3,\n",
    "    load_balancing_loss = True,\n",
    ")\n",
    "\n",
    "model = MoEModel(\n",
    "    config=config,\n",
    "    device=DEVICE,\n",
    "    importance = 0.9**torch.arange(config.n_features),\n",
    "    feature_probability = torch.tensor(0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa81f160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742619c5c18f40f284a0ab0b74ae5c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimize(model, n_batch=10, steps=50, print_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bea474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
